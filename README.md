# Deep Learning Challenge: Predicting Success for Alphabet Soup Charity Donations

Welcome to the deep-learning-challenge repository! This repository houses the code, data, and documentation for a comprehensive data analysis project focused on predicting the success of charitable donations for the Alphabet Soup Charity. We utilize deep learning techniques to analyze a dataset of donation records, aiming to determine which donation campaigns are more likely to be successful.

In this project, we employ a systematic approach to data exploration, cleaning, preprocessing, and modeling. We carefully examine the characteristics of individual features, perform necessary preprocessing steps, and implement a deep learning model with the Hyperband optimization technique to find the best model hyperparameters. Our detailed comments and annotations provide insights into our thought process and methodology, making this repository a valuable resource for data science enthusiasts, researchers, and machine learning practitioners.

Below you'll find a brief description of the two main notebooks in this repository and a list of Python imports needed to execute the code. We hope you find this repository insightful and informative. Enjoy exploring the data and models!

AlphabetSoupCharity.ipynb is our cursory analysis of the data set, only modifying the data using the given prompts.

AlphabetSoupCharity_Optimization.ipynb is the primary file for our in-depth analysis of the dataset. In this notebook, we have conducted a comprehensive exploration of the data, including data cleaning, feature engineering, and preprocessing steps that transform the raw data into a format suitable for machine learning models. This file contains detailed comments and annotations that explain the reasoning and methodology behind each step, providing valuable insights into the data analysis process.

Some of the key components of this notebook include:
- A thorough examination of the distributions and characteristics of individual features, helping to identify patterns, outliers, and potential data quality issues.
- Preprocessing steps such as encoding categorical variables, transforming numerical features, and scaling the data to improve the performance of machine learning models.
- Implementation and tuning of a deep learning model using the Hyperband optimization technique, which systematically searches for the best model hyperparameters to achieve optimal predictive performance.
- Comprehensive notes and comments that provide context for the analysis, highlight key findings, and suggest potential future directions for research.

This file serves as a complete record of our data analysis workflow, capturing the entire process from initial data exploration to model evaluation. It can be used as a reference for further analysis and experimentation or adapted to other datasets and research questions.

Please consult the summary report, titled 'Beautiful Soup Neural Network Model Analysis,' for a concise overview of our data analysis, structural adjustments, and cleaning processes.

Python Imports Needed:</br>
[keras_tuner](https://keras.io/keras_tuner/)
[scikit-learn](https://scikit-learn.org/stable/)
[pandas](https://pandas.pydata.org/)
[tensorflow](https://www.tensorflow.org/)
[numpy](https://numpy.org/)

